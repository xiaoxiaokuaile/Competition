{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "color = sns.color_palette()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999\n",
    "from subprocess import check_output\n",
    "\n",
    "import warnings\n",
    "\n",
    "def ignore_warn(*args ,**kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20157, 32) (140, 3)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"./data/train_20171226.csv\")\n",
    "test = pd.read_csv(\"./data/yancheng_testB_20180224.csv\")\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#获取特征sale_month, sale_year\n",
    "train['sale_month'] = train['sale_date']%100\n",
    "train['sale_year'] = train['sale_date']//100%100\n",
    "test['sale_month'] = test['predict_date']%100\n",
    "test['sale_year'] = test['predict_date']//100%100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merge train dataset and fill test dataset\n",
    "merge_train = pd.DataFrame()\n",
    "all_class_id = train['class_id'].unique().tolist()\n",
    "for idx in all_class_id:\n",
    "    all_month = train['sale_date'][train['class_id']==idx].unique().tolist()\n",
    "    for mon in all_month:\n",
    "        max_val = train['sale_quantity'][train['class_id']==idx][train['sale_date']==mon].max()\n",
    "        sale_sum = train['sale_quantity'][train['class_id']==idx][train['sale_date']==mon].sum()\n",
    "        feat_val = train[train['class_id']==idx][train['sale_date']==mon][train['sale_quantity']==max_val]\n",
    "        feat_val['sale_quantity'] = sale_sum\n",
    "        merge_train = pd.concat([merge_train, feat_val[0:1]])\n",
    "#含有相同销量的同一class_id\n",
    "merge_train = merge_train.sort_values(by=['sale_date'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge_train = merge_train[['sale_date', 'class_id', 'sale_quantity', 'sale_month', 'sale_year']]\n",
    "cols = ['sale_date', 'class_id', 'sale_quantity', 'sale_month', 'sale_year']\n",
    "###############去除11月份 ##################\n",
    "merge_train = merge_train[merge_train['sale_month']!=11]\n",
    "test = test.ix[:,cols]\n",
    "test['sale_date'] = test['sale_date'].fillna(201712)\n",
    "test['sale_date'] = test['sale_date'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "less than 10: sale_quantity    34\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count = merge_train[['class_id','sale_quantity']].groupby(['class_id'], as_index=1).count().sort_values(['sale_quantity'])\n",
    "print('less than 10:',count[count['sale_quantity']<14].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5195, 5) (140, 5)\n"
     ]
    }
   ],
   "source": [
    "print(merge_train.shape, test.shape)\n",
    "class_12 = count[count['sale_quantity']<14]\n",
    "class_12 = class_12.index.tolist()\n",
    "all_data = pd.concat((merge_train, test)).reset_index(drop=True)\n",
    "for idx in class_12:\n",
    "    li = []\n",
    "    li = all_data[all_data['class_id']==idx].index.tolist()\n",
    "    all_data.drop(all_data.index[li],inplace=True)\n",
    "    all_data = all_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rolling(df,roll,window):\n",
    "    last=roll(df,window=window).tolist()\n",
    "    last=[np.NaN]+last\n",
    "    last.pop()\n",
    "    return last\n",
    "\n",
    "new = pd.DataFrame()\n",
    "for a in all_class_id:\n",
    "    df = all_data[all_data['class_id'] == a]\n",
    "    df['last_1_sum'] = rolling(df['sale_quantity'], pd.rolling_sum, window=1)\n",
    "    df['last_2_sum'] = rolling(df['sale_quantity'], pd.rolling_sum, window=2)\n",
    "    df['last_3_sum'] = rolling(df['sale_quantity'], pd.rolling_sum, window=3)\n",
    "    df['last_4_sum'] = rolling(df['sale_quantity'], pd.rolling_sum, window=4)\n",
    "    df['last_5_sum'] = rolling(df['sale_quantity'], pd.rolling_sum, window=5)\n",
    "    df['last_6_sum'] = rolling(df['sale_quantity'], pd.rolling_sum, window=6)\n",
    "    df['last_7_sum'] = rolling(df['sale_quantity'], pd.rolling_sum, window=7)\n",
    "    df['last_8_sum'] = rolling(df['sale_quantity'], pd.rolling_sum, window=8)\n",
    "    df['last_9_sum'] = rolling(df['sale_quantity'], pd.rolling_sum, window=9)\n",
    "    df['last_10_sum'] = rolling(df['sale_quantity'], pd.rolling_sum, window=10)\n",
    "    df['last_11_sum'] = rolling(df['sale_quantity'], pd.rolling_sum, window=11)\n",
    "    df['last_12_sum'] = rolling(df['sale_quantity'], pd.rolling_sum, window=12)\n",
    "    df['last_13_sum'] = rolling(df['sale_quantity'], pd.rolling_sum, window=13)\n",
    "    \n",
    "    df['last_5_mean'] = rolling(df['sale_quantity'], pd.rolling_mean, window=5)\n",
    "    \n",
    "    df['last_5_std'] = rolling(df['sale_quantity'], pd.rolling_std, window=5)\n",
    "    \n",
    "    df['move_1'] = df['last_1_sum']\n",
    "    df['move_2'] = df['last_2_sum'] - df['last_1_sum']\n",
    "    df['move_3'] = df['last_3_sum'] - df['last_2_sum']\n",
    "    df['move_4'] = df['last_4_sum'] - df['last_3_sum']\n",
    "    df['move_5'] = df['last_5_sum'] - df['last_4_sum']\n",
    "    \n",
    "    df['move_9'] = df['last_9_sum'] - df['last_8_sum']\n",
    "    \n",
    "    df['move_11'] = df['last_11_sum'] - df['last_10_sum']\n",
    "    df['move_12'] = df['last_12_sum'] - df['last_11_sum']\n",
    "    df['move_13'] = df['last_13_sum'] - df['last_12_sum']\n",
    "    \n",
    "    \n",
    "    df['diff_12'] = df['move_11'] - df['move_12']\n",
    "    #df['diff_13'] = df['move_11'] - df['move_13']\n",
    "    \n",
    "    #对于12月份的滑动值特殊处理,因为不存才201711的特征\n",
    "    #diff = df['move_11'][df['sale_month']==12] - df['move_13'][df['sale_month']==12]\n",
    "    #df['diff_12'][df['sale_month']==12] = diff\n",
    "    #move = df['last_11_sum'][df['sale_month']==12] - df['last_10_sum'][df['sale_month']==12]\n",
    "    #df['move_12'][df['sale_month']==12] = move\n",
    "    \n",
    "    new = pd.concat([new, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = new.drop(['last_1_sum', 'last_2_sum', 'last_3_sum', 'last_4_sum', 'last_5_sum',\n",
    "                 'last_6_sum', 'last_7_sum', 'last_8_sum', 'last_9_sum', 'last_10_sum',\n",
    "                 'last_11_sum', 'last_12_sum', 'last_13_sum', 'move_12', 'move_13'], axis=1)\n",
    "test = data[data['sale_quantity'].isnull()]\n",
    "train_X = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3656, 13) (3550, 13) (3550,) (106, 13) 106 106\n"
     ]
    }
   ],
   "source": [
    "#spilt dataset\n",
    "val_data = train_X[train_X['sale_date']==201710]\n",
    "val_data = val_data.drop(['sale_date'], axis=1)\n",
    "\n",
    "test = test.drop(['sale_date', 'sale_quantity'], axis=1)\n",
    "\n",
    "#训练集\n",
    "train_x = train_X[train_X['sale_date']!=201710]\n",
    "train_y = train_x['sale_quantity']\n",
    "train_x = train_x.drop(['sale_date', 'sale_quantity'], axis=1)\n",
    "\n",
    "#最终训练数据集\n",
    "y = train_X['sale_quantity']\n",
    "train_X = train_X.drop(['sale_date', 'sale_quantity'], axis=1)\n",
    "\n",
    "print(train_X.shape, train_x.shape, train_y.shape, test.shape, len(train_x['class_id'].unique().tolist()),len(test['class_id'].unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import ElasticNet,Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "def xgb_Regressor(train_x, train_y, val_data, train_X, y):\n",
    "    xgb_model = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=1200,\n",
    "                             reg_alpha=0.1640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "    xgb_model.fit(train_x, train_y)\n",
    "    pred_val = xgb_model.predict(val_data.drop(['sale_quantity'],axis=1))\n",
    "    score = rmsle(val_data['sale_quantity'], pred_val)\n",
    "    xgb_model.fit(train_X, y)\n",
    "    \n",
    "    return xgb_model, score, pred_val\n",
    "\n",
    "def lgb_Regressor(train_x, train_y, val_data, train_X, y):\n",
    "    lgb_model = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=360,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 10)\n",
    "    lgb_model.fit(train_x, train_y)\n",
    "    pred_val = lgb_model.predict(val_data.drop(['sale_quantity'],axis=1))\n",
    "    score = rmsle(val_data['sale_quantity'], pred_val)\n",
    "    lgb_model.fit(train_X, y)\n",
    "    \n",
    "    return lgb_model, score, pred_val\n",
    "def base_model():\n",
    "    ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "    lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "\n",
    "    return ENet,lasso\n",
    "\n",
    "def gboost_Regressor(train_x, train_y, val_data, train_X, y):\n",
    "    gb_model = GradientBoostingRegressor(n_estimators=3600, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=20, min_samples_split=20, \n",
    "                    loss='huber', random_state =5)\n",
    "    gb_model.fit(train_x, train_y)\n",
    "    pred_val = gb_model.predict(val_data.drop(['sale_quantity'],axis=1))\n",
    "    score = rmsle(val_data['sale_quantity'], pred_val)\n",
    "    gb_model.fit(train_X, y)\n",
    "    \n",
    "    return gb_model, score, pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBOOSTRegressor开始训练...\n",
      "152.774456446\n"
     ]
    }
   ],
   "source": [
    "print(\"XGBOOSTRegressor开始训练...\")\n",
    "xgb_model, score, xgb_train_pred = xgb_Regressor(train_x, train_y, val_data, train_X, y)\n",
    "print(score)\n",
    "xgb_pred = xgb_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMRegressor开始训练...\n",
      "130.382680099\n"
     ]
    }
   ],
   "source": [
    "print(\"LGBMRegressor开始训练...\")\n",
    "lgb_model,score, lgb_train_pred= lgb_Regressor(train_x, train_y, val_data, train_X, y)\n",
    "print(score)\n",
    "lgb_pred = lgb_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDBTRegressor开始训练...\n",
      "118.19399117\n"
     ]
    }
   ],
   "source": [
    "print(\"GDBTRegressor开始训练...\")\n",
    "gb_model,score, gb_train_pred = gboost_Regressor(train_x, train_y, val_data, train_X, y)\n",
    "print( score)\n",
    "gb_pred = gb_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENet: 144.314851514\n",
      "lasso: 144.318756857\n"
     ]
    }
   ],
   "source": [
    "ENet,lasso= base_model()\n",
    "    \n",
    "ENet.fit(train_X, y)\n",
    "enet_pred = ENet.predict(val_data.drop(['sale_quantity'],axis=1))\n",
    "print(\"ENet:\", rmsle(val_data['sale_quantity'], enet_pred))\n",
    "    \n",
    "lasso.fit(train_X, y)\n",
    "lasso_pred = lasso.predict(val_data.drop(['sale_quantity'],axis=1))\n",
    "print(\"lasso:\", rmsle(val_data['sale_quantity'], lasso_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking...\n",
      "114.153556252\n",
      "117.934953099\n"
     ]
    }
   ],
   "source": [
    "# ####Stacking####\n",
    "print('Stacking...')\n",
    "stacked_averaged_models = StackingRegressor(\n",
    "regressors=[ENet,lasso, lgb_model, gb_model],\n",
    "meta_regressor= xgb_model\n",
    ")\n",
    "stacked_averaged_models.fit(train_x, train_y)\n",
    "stacked_train_pred = stacked_averaged_models.predict(val_data.drop(['sale_quantity'],axis=1))\n",
    "stacked_averaged_models.fit(train_X, y)\n",
    "stacked_pred = stacked_averaged_models.predict(test.values)\n",
    "print(rmsle(val_data['sale_quantity'], stacked_train_pred))\n",
    "print(rmsle(val_data['sale_quantity'], stacked_train_pred*0.30 + gb_train_pred*0.30 + \n",
    "       lgb_train_pred*0.20 + xgb_train_pred*0.20))\n",
    "ensemble = stacked_pred*0.30 + gb_pred*0.30  + lgb_pred*0.20 + xgb_pred*0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#submission\n",
    "test['sale_quantity'] = ensemble\n",
    "cols = test['class_id'].unique().tolist()\n",
    "sub = pd.read_csv(\"./data/yancheng_testB_20180224.csv\")\n",
    "for idx in cols:\n",
    "    sale = test['sale_quantity'][test['class_id']==idx]\n",
    "    sub['predict_quantity'][sub['class_id']==idx] = list(sale)[0]\n",
    "for idx in class_12:\n",
    "    sale = merge_train['sale_quantity'][merge_train['class_id']==idx][merge_train['sale_date']==201710]\n",
    "    sub['predict_quantity'][sub['class_id']==idx] = list(sale)[0]*1.3\n",
    "sub.to_csv('submission_hejian_27.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106, 13)"
      ]
     },
     "execution_count": 1203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>822405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1142964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1241977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1309049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1085810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id\n",
       "0   822405\n",
       "1  1142964\n",
       "2  1241977\n",
       "3  1309049\n",
       "4  1085810"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"first_test_index_20180131.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['type'] = 'galaxy'\n",
    "test.to_csv(\"tianwen_galaxy.csv\", index=False, header=False)\n",
    "test['type'] = 'qso'\n",
    "test.to_csv(\"tianwen_qso.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
